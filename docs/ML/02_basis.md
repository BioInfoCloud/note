## 机器学习的基本概念

### 一、机器学习方法流程

以有监督学习方法为例：

监督学习：事先提供已知结果的样本，按照样本学习建立模型。

1、输入数据（Raw data）

2、特征工程（Deploy in）

3、模型训练（Features）

4、模型部署（Models）

5、模型应用（production）

首先，有结果的输入数据（有结果的样本数据），基于这个数据建立一些新特征（特征工程）。特征有可能和输入的数据一样，那输入的数据属性就是特征，有时可能要做一些修整。通过特征进行模型训练得到既定的公式，然后通过评估之后进行部署，然后进行应用。

### 二、输入空间与输出空间

输入空间(Input Space):将输入的所有可能取值的集合称作输入空间。

输出空间（Output Space)︰将输出的所有可能取值的集合称作输出空间。

比如：

1、采集了一些父子的身，对这些数据进行建模，然后使用模型，根据输入的父亲的身高去预测其子身高的取值。

父亲的身高实际上就是输入的特征，父亲身高输入所有可能的集合就是输入空间。儿子的身高就是输出结果，取值组成的集合就是输出空间。

2、搜集了泰坦尼克号上乘客的相关信息，对这些数据进行建模，使用模型去预测某个乘客是否能够生还、

这里 Survived 数值型 存货情况 存活：1，死亡：1 实际上就是最后输出空间。其他的都属于输入空间。

- 输入空间和输出空间可以是有限元素的集合，也可以是整个欧氏空间
- 输入空间和输出空间可以是连续值集合，也可以是离散值集合
- 输入空间和输出空间可以是同一个空间，也可以是不同空间
- 通常输出空间会比输入空间小

### 三、特征空间

特征(Feature ):即属性。每个输入实例的各个组成部分（属性）称作原始特征，基于原始特征还可以扩展出更多的衍生特征。

特征向量(Feature Vector) :由多个特征组成的集合，称作特征向量。

特征空间（Feature Space):将特征向量存在的空间称作特征空间。

比如：

1、 特征：父亲身高 165

特征向量：一维，（165）

2、特征:

PassengerId, Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked

特征向量:

十一维，(1,3,"Braund，Mr. Owen Harris","male",22,1,0,"A/5 21171",7.25,"","S

简化一下比如只输入性别和年龄，那么输入空间就是 Sex，Age 所有的可能取值组合。

然后扩展一下， Fare就是票的价钱，是一个连续值，是原始特征。在分析或建模过程中需要要把它做成 C level H、M、L，因为在建模过程中可能并不使用原始（Fare）价钱，而是使用 C level 就是延伸特征。

特征: Sex= "male”,Age=22,C_level= “L”

- 特征空间中每一维都对应了一个特征(属性)
- 特征空间可以和输入空间相同，也可以不同
- 需将将实例从输入空间映射到特征空间
- 模型实际上是定义于特征空间之上的

### **四、假设空间的定义**

假设空间 (Hypothesis Space)：由输入空间到输出空间的映射的集合，称作假设空间。

假设空间的不同定义：

监督学习的目的在于学习一个由输入到输出的映射，这一映射由模型来表示。换句话说，学习的目的就在于找到最好的这样的模型。模型属于由输入空间到输出空间的映射集合，这个集合就是 统计学习方假设空间。假设空间的确定意味着学习范围的确定。

--李航《统计学习方法》

The hypothesis space,which defines the class of functions mapping the input space to th e output space. That is,the functions operate on the feature vectors of the input object s, and make predictions according to the format of the output space.

--李铁岩 Learning to Rank for Information Retrieval

假设空间指的是问题所有假设组成的空间，我们可以把学习过程看作是在假设空间中搜索的过程，搜索目标是寻找与训练集“匹配”的假设。--周志华《机器学习》

### **五、举例**

举例：某商品的浏览、购买记录中，记录了性别、信用度及是否购买，基于数据建模。其中Gender 取值为(Female,Male)，Credit 取值为(High, Mediun,Low) Buy的取值为(TRUE, FALSE)

| Gender | credit | Buy   |
| ------ | ------ | ----- |
| Female | High   | TRUE  |
| Female | Low    | TRUE  |
| Male   | Low    | FALSE |
| Male   | Medium | FALSE |

输入记录中所有可能出现的值的组合为2×3=6个，列表如下：

| Female | High   |
| ------ | ------ |
| Female | Medium |
| Female | Low    |
| Male   | High   |
| Male   | Medium |
| Male   | Low    |

上述每个组合最终结果都可能有两个，即True或False:

| Female | High   | TRUE  |
| ------ | ------ | ----- |
| Female | Medium | TRUE  |
| Female | Low    | TRUE  |
| Male   | High   | TRUE  |
| Male   | Medium | TRUE  |
| Male   | Low    | TRUE  |
| Female | High   | FALSE |
| Female | Medium | FALSE |
| Female | Low    | FALSE |
| Male   | High   | FALSE |
| Male   | Medium | FALSE |
| Male   | Low    | FALSE |
|        |        |       |

针对每一种可能的输入，都能找到一个映射，对应了输出空间中某个输出。总共可能出现的假设个数：2×2×2×2×2×2=2^6^通常还会加上一个特殊的全空假设，即2^6^+1。所以上表不属于假设空间。

### 六、机器学习方法三要素

机器学习方法通常都是由模型、策略和算法三部分构成:方法=模型+策略+算法

（1）模型:输入空间到输出空间的映射关系。学习过程即为从假设空间中搜索适合当前数据的假设。

（2）策略:从假设空间众多的假设中选择到最优的模型的学习标准或规则。

（3）算法:学习模型的具体的计算方法，通常是求解最优化问题。

#### 1、模型

模型:输入空间到输出空间的映射关系。学习过程即为从假设空间中搜索适合当前数据的假设。分析当前需要解决的问题，确定模型。

需要解决什么问题

预测分类   分类（Classification）

预测取值   回归（Regression）

发现结构   聚类（Clustering）

发现异常数据 异常检测（Anomaly Detection）

#### 2、策略

策略:从假设空间众多的假设中选择到最优的模型的学习标准或规则。

要从假设空间中选择一个最合适的模型出来，需要解决以下问题:

（1）评估某个模型对单个训练样本的效果

（2）评估某个模型对训练集的整体效果

（3）评估某个模型对包括训练集、预测集在内的所有数据的整体效果

定义几个指标用来衡量上述问题:

损失函数:0-1损失函数、平方损失函数、绝对损失函数、对数损失函数等

风险函数:经验风险、期望风险、结构风险

基本策略：

经验风险最小（EMR :Empirical Risk Minimization)

结构风险最小（SRM : Structural Risk Minimization)

#### **3、损失函数：**

损失函数(Loss Function)：用来衡量预测结果和真实结果之间的差距，其值越小，代表预测结果和真实结果越一致。通常是一个非负实值函数，通过各种方式缩小损失函数的过程被称作优化。损失函数记做L(Y,f(x))。

- 0-1损失函数（0-1LF）：

预测值和实际值精确相等则“没有损失”为0，否则意味着“完全损失”，为1预测值和实际值精确相等有些过于严格，可以采用两者的差小于某个國值的方式。

​       1,Y≠f(X)

L(Y,f(X))=  0,Y=f(X)

​        1,|Y-f(X)|>=T

L(Y,f(X))= 0,|Y=f(X)|<T

对于相同的预测结果，两个损失函数严格程度不同。设T=0.5，则有：

| Y    | F(X) | L    | L’   |
| ---- | ---- | ---- | ---- |
| 0    | 0.3  | 1    | 0    |
| 1    | 0.8  | 1    | 0    |
| 1    | 1.2  | 1    | 0    |
| 0    | 0    | 0    | 0    |

前者相当于后者的一个特殊情况 T=0

- 绝对值损失函数(Absolute LF):

预测结果与真实结果差的绝对值。简单易懂,但是计算不方便。

L(Y,f(X))=|Y-f(X)|

- 平方损失函数(Quadratic LF):

预示结果与真实结果差的平方。

L(Y,f(X))=(Y-f(X))²

平方损失函数优势有：

- 每个样本的误差都是正的，累加不会被抵消
- 平方对于大误差的惩罚大于小误差
- 数学计算简单、友好，导数为一次函数

| Y    | F(X) | ALF  | SLF  |
| ---- | ---- | ---- | ---- |
| 0    | 0.3  | 0.3  | 0.09 |
| 1    | 0.8  | 0.2  | 0.04 |
| 1    | 1.2  | 0.2  | 0.04 |
| 0    | 0    | 1    | 0    |

（四）对数损失函数(Logarithmic LF)或对数似然损失函数(log-likehood loss function)：

对数函数具有单调性，在求最优化问题时，结果与原始目标一致。可将乘法转化为加法，简化计算：

L(Y，P(Y∣X))= -logP(Y∣X)

（五）指数损失函数(Exponential LF)：

单调性、非负性的优良性质，使得越接近正确结果误差越小    

L(Y,f(x))=

（六）折叶损失函数(Hings LF):

   也称铰链损失，对于判定边界附近点的惩罚力度较高，常见于SVM

   L(f(x))=max(0,1-f(x))

不同的损失函数有不同的特点，适用于不同的场景

- 0-1：理想状况模型
- Log：逻辑回归、交叉熵
- Squared:线性回归
- Exponential:AdaBoosting
- Hinge:SVM、soft margin